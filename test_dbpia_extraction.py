import asyncio
import sys

# ArchiDB ê²½ë¡œ ì¶”ê°€
sys.path.append('/Users/seunghakwoo/Library/CloudStorage/GoogleDrive-caadwoo@gmail.com/ë‚´ ë“œë¼ì´ë¸Œ/code/ArchiDB/backend')

from crawlers.ddpia_crawler import DDpiaCrawler


async def test_full_extraction():
    """Dbpia ì™„ì „í•œ ì´ˆë¡ ë° ì›ë¬¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    api_key = '9fd0da6c4c2b3c75bb71611ed333566d'

    print('=== Dbpia ì™„ì „í•œ ì´ˆë¡ ë° ì›ë¬¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ===\n')

    try:
        async with DDpiaCrawler(api_key) as crawler:
            # ë¨¼ì € API ì—°ê²° í…ŒìŠ¤íŠ¸
            print('ğŸ” API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...')
            basic_result = await crawler.search_papers(
                keyword='ì»´í“¨í„°',  # ë” ì¼ë°˜ì ì¸ í‚¤ì›Œë“œ
                page_size=3
            )

            print(f'ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼: {len(basic_result["papers"])}ê°œ')

            if len(basic_result["papers"]) == 0:
                print('âš ï¸  APIì—ì„œ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë¥¼ ë°”ê¿”ì„œ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.')

                # ì¹´í…Œê³ ë¦¬ ì—†ì´ ì‹œë„
                result = await crawler.search_papers(
                    keyword='ì„¤ê³„',
                    page_size=5,
                    enhance_abstracts=True,
                    extract_full_text=False
                )
            else:
                print('âœ… API ì—°ê²° ì„±ê³µ! ì™„ì „í•œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.')

                # ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸ (ì´ˆë¡ ë° ì›ë¬¸)
                result = await crawler.search_papers(
                    keyword='ì»´í“¨í„°',
                    page_size=2,  # ì‘ì€ ìˆ˜ë¡œ ì‹œì‘
                    enhance_abstracts=True,
                    extract_full_text=True
                )

            print(f'âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(result["papers"])}ê°œ ë…¼ë¬¸\n')

            for i, paper in enumerate(result['papers'], 1):
                print(f'{"="*60}')
                print(f'ë…¼ë¬¸ {i}: {paper["title"]}')
                print(f'ì €ì: {paper["authors"]}')
                print(f'ë°œí–‰: {paper["publication"]} ({paper.get("publication_year", "N/A")})')
                print(f'{"="*60}')

                # ì´ˆë¡ ì •ë³´
                print('\nğŸ“„ ì´ˆë¡ ì •ë³´:')
                print(f'  - ì´ˆë¡ ê°œì„ : {"âœ…" if paper.get("abstract_enhanced", False) else "âŒ"}')
                print(f'  - ì´ˆë¡ í’ˆì§ˆ: {paper.get("abstract_quality_score", 0):.1f}/10')

                abstract = paper.get('abstract', '')
                if abstract:
                    print(f'  - ì´ˆë¡ ê¸¸ì´: {len(abstract)}ì')
                    print(f'  - ì´ˆë¡ ë‚´ìš©: {abstract[:300]}...')
                else:
                    print('  - ì´ˆë¡: ì—†ìŒ')

                # ì›ë¬¸ ì •ë³´
                print('\nğŸ“– ì›ë¬¸ ì •ë³´:')
                extraction_status = paper.get('extraction_status', 'pending')
                status_icon = {'success': 'âœ…', 'failed': 'âŒ', 'pending': 'â³'}.get(extraction_status, 'â“')
                print(f'  - ì›ë¬¸ ì¶”ì¶œ: {status_icon} {extraction_status}')

                if paper.get('text_quality_score'):
                    print(f'  - ì›ë¬¸ í’ˆì§ˆ: {paper["text_quality_score"]:.1f}/10')

                if paper.get('pdf_local_path'):
                    print(f'  - PDF íŒŒì¼: {paper["pdf_local_path"]}')
                    print(f'  - íŒŒì¼ í¬ê¸°: {paper.get("pdf_file_size", 0):,} bytes')

                full_text = paper.get('full_text', '')
                if full_text:
                    print(f'  - ì›ë¬¸ ê¸¸ì´: {len(full_text):,}ì')
                    print(f'  - ì›ë¬¸ ë¯¸ë¦¬ë³´ê¸°: {full_text[:500]}...')
                else:
                    print('  - ì›ë¬¸: ì¶”ì¶œë˜ì§€ ì•ŠìŒ')

                print(f'\n{"="*60}\n')

            # ìš”ì•½ í†µê³„
            total_papers = len(result['papers'])
            enhanced_abstracts = sum(1 for p in result['papers'] if p.get('abstract_enhanced', False))
            successful_extractions = sum(1 for p in result['papers'] if p.get('extraction_status') == 'success')

            print('ğŸ“Š ì¶”ì¶œ ê²°ê³¼ ìš”ì•½:')
            print(f'  - ì´ ë…¼ë¬¸ ìˆ˜: {total_papers}ê°œ')

            if total_papers > 0:
                print(f'  - ì´ˆë¡ ê°œì„ : {enhanced_abstracts}/{total_papers}ê°œ ({enhanced_abstracts/total_papers*100:.1f}%)')
                print(f'  - ì›ë¬¸ ì¶”ì¶œ: {successful_extractions}/{total_papers}ê°œ ({successful_extractions/total_papers*100:.1f}%)')

                avg_abstract_quality = sum(p.get('abstract_quality_score', 0) for p in result['papers']) / len(result['papers'])
                print(f'  - í‰ê·  ì´ˆë¡ í’ˆì§ˆ: {avg_abstract_quality:.1f}/10')

                text_qualities = [p.get('text_quality_score', 0) for p in result['papers'] if p.get('text_quality_score')]
                if text_qualities:
                    avg_text_quality = sum(text_qualities) / len(text_qualities)
                    print(f'  - í‰ê·  ì›ë¬¸ í’ˆì§ˆ: {avg_text_quality:.1f}/10')
            else:
                print('  - ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.')

    except Exception as e:
        print(f'âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_full_extraction())
