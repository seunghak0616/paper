from __future__ import annotations

import argparse
import os
import sys

# Add the project root to the Python path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import os
from pathlib import Path

import openai
from pypdf import PdfReader
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from tqdm import tqdm

from app.models import Paper, PaperChunk

# --- DB ì—°ê²° ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ìŠ¤í¬ë¦½íŠ¸ ìµœìƒë‹¨ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ê°•ì œë¡œ ì„¤ì • ---
os.environ['DATABASE_URL'] = "postgresql://user:password@localhost:5432/papers"

# --- ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent.parent
# OpenAI í´ë¼ì´ì–¸íŠ¸ëŠ” .env íŒŒì¼ì˜ OPENAI_API_KEYë¥¼ ìë™ìœ¼ë¡œ ì½ìŒ
client = openai.OpenAI()
CHUNK_SIZE = 500  # í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆŒ ê¸€ì ìˆ˜ ê¸°ì¤€
EMBEDDING_MODEL = "text-embedding-ada-002"


def split_text_into_chunks(text: str, chunk_size: int) -> list[str]:
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
    if not text:
        return []

    # ë¨¼ì € ë¬¸ë‹¨ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ë„ˆë¬´ ê¸´ ë¬¸ë‹¨ì€ ë¬¸ì¥ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    chunks = []
    paragraphs = text.split("\n\n")
    for p in paragraphs:
        if len(p) <= chunk_size:
            chunks.append(p.strip())
        else:
            sentences = p.split(". ")
            current_chunk = ""
            for s in sentences:
                if len(current_chunk) + len(s) + 1 > chunk_size:
                    chunks.append(current_chunk.strip())
                    current_chunk = s + ". "
                else:
                    current_chunk += s + ". "
            if current_chunk:
                chunks.append(current_chunk.strip())

    return [c for c in chunks if c]


def process_pdf_and_embed(pdf_path: Path, db_session) -> None:
    """ê°œë³„ PDFë¥¼ ì²˜ë¦¬í•˜ê³ , ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì„ë² ë”©ê³¼ í•¨ê»˜ DBì— ì €ì¥"""
    if not pdf_path.exists():
        print(f"âš ï¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    # PDF íŒŒì¼ëª…ì—ì„œ '.pdf' í™•ì¥ìë¥¼ ì œê±°í•˜ì—¬ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
    title = pdf_path.stem

    # 1. Paper ë ˆì½”ë“œ ìƒì„± ë˜ëŠ” í™•ì¸
    existing_paper = db_session.query(Paper).filter_by(title=title).first()
    if existing_paper:
        print(f"ì´ë¯¸ ì²˜ë¦¬ëœ ë…¼ë¬¸ì…ë‹ˆë‹¤: {title}")
        return

    db_paper = Paper(
        title=title,
        pdf_path=str(pdf_path.resolve()),
    )
    db_session.add(db_paper)
    db_session.commit()
    db_session.refresh(db_paper)

    print(f"ğŸ“„ '{db_paper.title}' ì²˜ë¦¬ ì¤‘...")

    # 2. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
    try:
        reader = PdfReader(pdf_path)
        # ì „ì²´ í˜ì´ì§€ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ
        full_text = "\n".join([page.extract_text() for page in reader.pages])
    except Exception as e:
        print(f"ğŸ”¥ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {pdf_path}, ì˜¤ë¥˜: {e}")
        # ì‹¤íŒ¨ ì‹œ ë¡¤ë°±í•˜ê³  ë‹¤ìŒ íŒŒì¼ë¡œ ì§„í–‰
        db_session.rollback()
        return

    # 3. í…ìŠ¤íŠ¸ ì²­í‚¹
    chunks = split_text_into_chunks(full_text, CHUNK_SIZE)
    if not chunks:
        print(f"â„¹ï¸ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    print(f"  - {len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë¨")

    # 4. ê° ì²­í¬ ì„ë² ë”© ìƒì„± ë° ì €ì¥
    try:
        # í•œ ë²ˆì— ì—¬ëŸ¬ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ API í˜¸ì¶œ ìµœì†Œí™”
        response = client.embeddings.create(input=chunks, model=EMBEDDING_MODEL)
        embeddings = [item.embedding for item in response.data]

        for i, chunk_text in enumerate(chunks):
            db_chunk = PaperChunk(
                paper_id=db_paper.id,
                chunk_text=chunk_text,
                embedding=embeddings[i],
                page_number=i // 5 + 1, # ì„ì‹œ í˜ì´ì§€ ë²ˆí˜¸
            )
            db_session.add(db_chunk)

        db_session.commit()
        print("  - âœ… ì„ë² ë”© ì €ì¥ ì™„ë£Œ")

    except Exception as e:
        print(f"ğŸ”¥ ì„ë² ë”© ìƒì„± ë˜ëŠ” ì €ì¥ ì‹¤íŒ¨: {e}")
        db_session.rollback()


def main(pdf_directory: str):
    """
    ì§€ì •ëœ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  PDF íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  DBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    target_dir = Path(pdf_directory)
    if not target_dir.is_dir():
        print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_directory}")
        return

    pdf_files = list(target_dir.rglob("*.pdf"))
    if not pdf_files:
        print(f"ğŸ¤· ë””ë ‰í† ë¦¬ì—ì„œ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_directory}")
        return

    print(f"ì´ {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # ì´ ìŠ¤í¬ë¦½íŠ¸ì—ì„œë§Œ ì‚¬ìš©í•  DB ì—°ê²°ì„ ëª…ì‹œì ìœ¼ë¡œ ìƒì„±
    engine = create_engine(os.environ['DATABASE_URL'])
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

    db_session = SessionLocal()
    try:
        with tqdm(total=len(pdf_files), desc="ë¡œì»¬ PDF ì²˜ë¦¬ ì¤‘") as pbar:
            for pdf_path in pdf_files:
                process_pdf_and_embed(pdf_path, db_session)
                pbar.update(1)

        print("âœ… ëª¨ë“  ë…¼ë¬¸ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    finally:
        db_session.close()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ì§€ì •ëœ ë””ë ‰í† ë¦¬ì˜ PDF íŒŒì¼ë“¤ì„ ì²˜ë¦¬í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í•©ë‹ˆë‹¤.")
    parser.add_argument("directory", type=str, help="PDF íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    args = parser.parse_args()

    main(args.directory)
