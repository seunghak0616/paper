import asyncio
import sys

# ArchiDB ê²½ë¡œ ì¶”ê°€
sys.path.append('/Users/seunghakwoo/Library/CloudStorage/GoogleDrive-caadwoo@gmail.com/ë‚´ ë“œë¼ì´ë¸Œ/code/ArchiDB/backend')


async def demo_extraction_capabilities():
    """ì´ˆë¡ ë° ì›ë¬¸ ì¶”ì¶œ ê¸°ëŠ¥ ì‹œì—° (ë°ëª¨ ë°ì´í„°)"""

    print('=== Dbpia ì™„ì „í•œ ì´ˆë¡ ë° ì›ë¬¸ ì¶”ì¶œ ê¸°ëŠ¥ ì‹œì—° ===\n')

    # ë°ëª¨ ë…¼ë¬¸ ë°ì´í„°
    demo_papers = [
        {
            "title": "ìŠ¤ë§ˆíŠ¸ ê±´ì¶• ì„¤ê³„ë¥¼ ìœ„í•œ IoT ê¸°ë°˜ í™˜ê²½ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ",
            "authors": "ê¹€ê±´ì¶•, ë°•ì„¤ê³„, ì´ìŠ¤ë§ˆíŠ¸",
            "publisher": "í•œêµ­ê±´ì¶•í•™íšŒ",
            "publication": "ëŒ€í•œê±´ì¶•í•™íšŒë…¼ë¬¸ì§‘",
            "dbpia_id": "NODE02345678",
            "abstract": "ë³¸ ì—°êµ¬ëŠ” ìŠ¤ë§ˆíŠ¸ ê±´ì¶• í™˜ê²½ì—ì„œ...",  # ê¸°ë³¸ API ì´ˆë¡ (ì§§ìŒ)
            "detail_url": "https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE02345678",
            "publication_year": 2023
        },
        {
            "title": "ì§€ì†ê°€ëŠ¥í•œ ë„ì‹œì„¤ê³„ë¥¼ ìœ„í•œ ë…¹ìƒ‰ ì¸í”„ë¼ ê³„íš ë°©ë²•ë¡ ",
            "authors": "ì •ë„ì‹œ, ê¹€ë…¹ìƒ‰, ë°•ì§€ì†",
            "publisher": "í•œêµ­ë„ì‹œì„¤ê³„í•™íšŒ",
            "publication": "ë„ì‹œì„¤ê³„í•™íšŒì§€",
            "dbpia_id": "NODE02345679",
            "abstract": "ë„ì‹œì˜ ì§€ì†ê°€ëŠ¥ì„±ì„ ìœ„í•´...",  # ê¸°ë³¸ API ì´ˆë¡ (ì§§ìŒ)
            "detail_url": "https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE02345679",
            "publication_year": 2023
        }
    ]

    print('ğŸ“š ë°ëª¨ ë…¼ë¬¸ ë°ì´í„°:')
    for i, paper in enumerate(demo_papers, 1):
        print(f'  {i}. {paper["title"]}')
    print()

    # ì´ˆë¡ í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜ ì‹œì—°
    def demo_validate_abstract_quality(abstract: str) -> float:
        """ì´ˆë¡ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë°ëª¨"""
        if not abstract:
            return 0.0

        score = 0.0

        # ê¸¸ì´ ì ìˆ˜ (3ì )
        length = len(abstract)
        if length >= 200:
            score += 3.0
        elif length >= 100:
            score += 2.0
        elif length >= 50:
            score += 1.0

        # êµ¬ì¡° ì ìˆ˜ (3ì )
        sentences = abstract.split('.')
        if len(sentences) >= 3:
            score += 3.0
        elif len(sentences) >= 2:
            score += 2.0
        elif len(sentences) >= 1:
            score += 1.0

        # í•™ìˆ  í‚¤ì›Œë“œ ì ìˆ˜ (4ì )
        keywords = ['ì—°êµ¬', 'ë¶„ì„', 'ê²°ê³¼', 'ê²°ë¡ ', 'ë°©ë²•', 'ëª©ì ', 'ì„¤ê³„', 'ê±´ì¶•']
        found_keywords = sum(1 for keyword in keywords if keyword in abstract)
        score += min(4.0, found_keywords * 0.5)

        return min(10.0, score)

    # ì™„ì „í•œ ì´ˆë¡ ë°ëª¨ ë°ì´í„°
    enhanced_abstracts = {
        "NODE02345678": """ë³¸ ì—°êµ¬ëŠ” ìŠ¤ë§ˆíŠ¸ ê±´ì¶• í™˜ê²½ì—ì„œ ì‹¤ì‹œê°„ í™˜ê²½ ëª¨ë‹ˆí„°ë§ì„ í†µí•œ ì—ë„ˆì§€ íš¨ìœ¨ì„± í–¥ìƒ ë°©ì•ˆì„ ì œì‹œí•œë‹¤. 
        IoT(Internet of Things) ì„¼ì„œ ë„¤íŠ¸ì›Œí¬ë¥¼ í™œìš©í•˜ì—¬ ê±´ë¬¼ ë‚´ ì˜¨ë„, ìŠµë„, ì¡°ë„, ê³µê¸°ì§ˆ ë“±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³ , 
        ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ìë™í™”ëœ í™˜ê²½ ì œì–´ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì˜€ë‹¤. 
        ì‹¤í—˜ ê²°ê³¼, ê¸°ì¡´ ê±´ë¬¼ ëŒ€ë¹„ ì—ë„ˆì§€ ì†Œë¹„ëŸ‰ì´ 25% ê°ì†Œí•˜ì˜€ìœ¼ë©°, ê±°ì£¼ìì˜ ë§Œì¡±ë„ê°€ 30% í–¥ìƒë˜ì—ˆë‹¤. 
        ë³¸ ì‹œìŠ¤í…œì€ í–¥í›„ ìŠ¤ë§ˆíŠ¸ ì‹œí‹° ê±´ì„¤ì— ì¤‘ìš”í•œ ê¸°ë°˜ ê¸°ìˆ ë¡œ í™œìš©ë  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëœë‹¤.""",

        "NODE02345679": """ê¸‰ì†í•œ ë„ì‹œí™”ì™€ ê¸°í›„ë³€í™”ë¡œ ì¸í•´ ë„ì‹œì˜ ì§€ì†ê°€ëŠ¥ì„± í™•ë³´ê°€ ì¤‘ìš”í•œ ê³¼ì œë¡œ ëŒ€ë‘ë˜ê³  ìˆë‹¤. 
        ë³¸ ì—°êµ¬ëŠ” ë…¹ìƒ‰ ì¸í”„ë¼ë¥¼ í™œìš©í•œ ì§€ì†ê°€ëŠ¥í•œ ë„ì‹œì„¤ê³„ ë°©ë²•ë¡ ì„ ì œì‹œí•œë‹¤. 
        ë„ì‹œ ê³µì›, ë…¹ìƒ‰ ì§€ë¶•, ë¹—ë¬¼ ì •ì›, íˆ¬ìˆ˜ì„± í¬ì¥ ë“±ì˜ ë…¹ìƒ‰ ì¸í”„ë¼ ìš”ì†Œë“¤ì„ ì²´ê³„ì ìœ¼ë¡œ ê³„íší•˜ê³  ë°°ì¹˜í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•˜ì˜€ë‹¤. 
        ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„ ê²°ê³¼, ì œì•ˆëœ ë°©ë²•ë¡ ì„ ì ìš©í•œ ì§€ì—­ì—ì„œ ë„ì‹œ ì—´ì„¬ í˜„ìƒì´ 3-5Â°C ì™„í™”ë˜ì—ˆê³ , 
        ì—°ê°„ ìš°ìˆ˜ ìœ ì¶œëŸ‰ì´ 40% ê°ì†Œí•˜ëŠ” íš¨ê³¼ë¥¼ í™•ì¸í•˜ì˜€ë‹¤. 
        ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ë…¹ìƒ‰ ì¸í”„ë¼ê°€ ë„ì‹œì˜ í™˜ê²½ì  ì§€ì†ê°€ëŠ¥ì„± í–¥ìƒì— í¬ê²Œ ê¸°ì—¬í•  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì¤€ë‹¤."""
    }

    # í…ìŠ¤íŠ¸ ì¶”ì¶œ í’ˆì§ˆ í‰ê°€ í•¨ìˆ˜
    def demo_calculate_extraction_quality(text: str) -> float:
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë°ëª¨"""
        if not text:
            return 0.0

        score = 0.0

        # ê¸¸ì´ ì ìˆ˜ (3ì )
        length = len(text)
        if length >= 5000:
            score += 3.0
        elif length >= 2000:
            score += 2.0
        elif length >= 500:
            score += 1.0

        # í•œê¸€/ì˜ë¬¸ ë¹„ìœ¨ ì ìˆ˜ (2ì )
        import re
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        total_chars = korean_chars + english_chars

        if total_chars > 0:
            if korean_chars / total_chars > 0.3 or english_chars / total_chars > 0.3:
                score += 2.0
            else:
                score += 1.0

        # êµ¬ì¡° ì ìˆ˜ (3ì )
        paragraphs = text.split('\n\n')
        if len(paragraphs) >= 10:
            score += 3.0
        elif len(paragraphs) >= 5:
            score += 2.0
        elif len(paragraphs) >= 2:
            score += 1.0

        # í•™ìˆ  í‚¤ì›Œë“œ ì ìˆ˜ (2ì )
        academic_keywords = ['ì—°êµ¬', 'ë¶„ì„', 'ê²°ê³¼', 'ê²°ë¡ ', 'ë°©ë²•', 'ì´ë¡ ', 'research', 'analysis']
        found_keywords = sum(1 for keyword in academic_keywords if keyword.lower() in text.lower())
        score += min(2.0, found_keywords * 0.25)

        return min(10.0, score)

    # ì›ë¬¸ ë°ëª¨ ë°ì´í„°
    full_text_samples = {
        "NODE02345678": """1. ì„œë¡ 
        
        ìŠ¤ë§ˆíŠ¸ ê±´ì¶•ì€ ì •ë³´í†µì‹ ê¸°ìˆ (ICT)ê³¼ ê±´ì¶• ê¸°ìˆ ì˜ ìœµí•©ì„ í†µí•´ ì—ë„ˆì§€ íš¨ìœ¨ì„±ê³¼ ê±°ì£¼ í¸ì˜ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ê±´ì¶• íŒ¨ëŸ¬ë‹¤ì„ì´ë‹¤.
        íŠ¹íˆ IoT ê¸°ìˆ ì˜ ë°œì „ê³¼ í•¨ê»˜ ê±´ë¬¼ ë‚´ ë‹¤ì–‘í•œ í™˜ê²½ ìš”ì†Œë“¤ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ê³  ì œì–´í•  ìˆ˜ ìˆëŠ” ìŠ¤ë§ˆíŠ¸ ì‹œìŠ¤í…œì˜ êµ¬ì¶•ì´ ê°€ëŠ¥í•´ì¡Œë‹¤.
        
        2. ì—°êµ¬ ë°©ë²•
        
        ë³¸ ì—°êµ¬ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ì€ IoT ì„¼ì„œë“¤ì„ í™œìš©í•˜ì˜€ë‹¤:
        - ì˜¨ë„/ìŠµë„ ì„¼ì„œ (DHT22)
        - ì¡°ë„ ì„¼ì„œ (TSL2561)
        - ê³µê¸°ì§ˆ ì„¼ì„œ (MQ-135)
        - ë™ì‘ ê°ì§€ ì„¼ì„œ (PIR)
        
        3. ì‹œìŠ¤í…œ êµ¬ì¶•
        
        ì„¼ì„œ ë„¤íŠ¸ì›Œí¬ëŠ” Zigbee í”„ë¡œí† ì½œì„ í†µí•´ êµ¬ì„±ë˜ì—ˆìœ¼ë©°, ì¤‘ì•™ ì œì–´ ì‹œìŠ¤í…œì€ Raspberry Pi 4ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°œë°œë˜ì—ˆë‹¤.
        ë°ì´í„°ë² ì´ìŠ¤ëŠ” MySQLì„ ì‚¬ìš©í•˜ì˜€ê³ , ì›¹ ì¸í„°í˜ì´ìŠ¤ëŠ” React.jsë¡œ êµ¬í˜„ë˜ì—ˆë‹¤.
        
        4. ì‹¤í—˜ ê²°ê³¼
        
        6ê°œì›”ê°„ì˜ ì‹¤í—˜ ê¸°ê°„ ë™ì•ˆ ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆë‹¤:
        - ì—ë„ˆì§€ ì†Œë¹„ëŸ‰ 25% ê°ì†Œ
        - ê±°ì£¼ì ë§Œì¡±ë„ 30% í–¥ìƒ
        - ì‹¤ë‚´ ê³µê¸°ì§ˆ ê°œì„  40%
        
        5. ê²°ë¡ 
        
        IoT ê¸°ë°˜ í™˜ê²½ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì´ ìŠ¤ë§ˆíŠ¸ ê±´ì¶•ì˜ í•µì‹¬ ê¸°ìˆ ë¡œì„œ í° ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŒì„ í™•ì¸í•˜ì˜€ë‹¤.""",

        "NODE02345679": """Abstract
        
        This study proposes a systematic methodology for sustainable urban design using green infrastructure.
        
        1. ì—°êµ¬ ë°°ê²½
        
        ë„ì‹œí™” ì§„í–‰ì— ë”°ë¥¸ í™˜ê²½ ë¬¸ì œë“¤ì´ ì‹¬ê°í•´ì§€ê³  ìˆë‹¤. íŠ¹íˆ ë„ì‹œ ì—´ì„¬ í˜„ìƒ, ëŒ€ê¸° ì˜¤ì—¼, í™ìˆ˜ ìœ„í—˜ ì¦ê°€ ë“±ì´ 
        ë„ì‹œ ê±°ì£¼ë¯¼ë“¤ì˜ ì‚¶ì˜ ì§ˆì„ í¬ê²Œ ì €í•˜ì‹œí‚¤ê³  ìˆë‹¤.
        
        2. ë…¹ìƒ‰ ì¸í”„ë¼ì˜ ê°œë…
        
        ë…¹ìƒ‰ ì¸í”„ë¼(Green Infrastructure)ëŠ” ìì—° ìƒíƒœê³„ì˜ ê¸°ëŠ¥ì„ í™œìš©í•˜ì—¬ ë„ì‹œ í™˜ê²½ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” 
        ì§€ì†ê°€ëŠ¥í•œ ì ‘ê·¼ ë°©ë²•ì´ë‹¤. ì£¼ìš” êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:
        
        2.1 ë„ì‹œ ê³µì›
        - ëŒ€ê·œëª¨ ì¤‘ì•™ê³µì›
        - ê·¼ë¦°ê³µì›
        - ì†Œê·œëª¨ í¬ì¼“íŒŒí¬
        
        2.2 ë…¹ìƒ‰ ì§€ë¶• ì‹œìŠ¤í…œ
        - ì§‘ì•½í˜• ë…¹ìƒ‰ ì§€ë¶•
        - ê´‘ë²”ìœ„í˜• ë…¹ìƒ‰ ì§€ë¶•
        - ìƒí™œí˜• ë…¹ìƒ‰ ì§€ë¶•
        
        2.3 ë¹—ë¬¼ ê´€ë¦¬ ì‹œì„¤
        - ë¹—ë¬¼ ì •ì› (Rain Garden)
        - íˆ¬ìˆ˜ì„± í¬ì¥
        - ìƒíƒœ ë„ë‘
        
        3. ê³„íš ë°©ë²•ë¡ 
        
        ë³¸ ì—°êµ¬ì—ì„œ ì œì•ˆí•˜ëŠ” ê³„íš ë°©ë²•ë¡ ì€ ë‹¤ìŒ 5ë‹¨ê³„ë¡œ êµ¬ì„±ëœë‹¤:
        1ë‹¨ê³„: í˜„í™© ë¶„ì„ ë° ë¬¸ì œì  ë„ì¶œ
        2ë‹¨ê³„: ë…¹ìƒ‰ ì¸í”„ë¼ ìš”ì†Œ ì„ ì •
        3ë‹¨ê³„: ê³µê°„ ë°°ì¹˜ ê³„íš
        4ë‹¨ê³„: ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„
        5ë‹¨ê³„: íš¨ê³¼ ê²€ì¦ ë° í”¼ë“œë°±
        
        4. ì‚¬ë¡€ ì—°êµ¬
        
        ì„œìš¸ì‹œ ë§ˆí¬êµ¬ ìƒì•”ë™ì„ ëŒ€ìƒìœ¼ë¡œ ì œì•ˆëœ ë°©ë²•ë¡ ì„ ì ìš©í•œ ê²°ê³¼:
        - ë„ì‹œ ì—´ì„¬ ì™„í™”: í‰ê·  4.2Â°C ê°ì†Œ
        - ìš°ìˆ˜ ìœ ì¶œëŸ‰ ê°ì†Œ: 42% ì €ê°
        - ëŒ€ê¸°ì§ˆ ê°œì„ : PM2.5 ë†ë„ 15% ê°ì†Œ
        - ìƒë¬¼ ë‹¤ì–‘ì„±: ì¡°ë¥˜ ì¢… ìˆ˜ 35% ì¦ê°€
        
        5. ê²°ë¡  ë° ì œì–¸
        
        ë…¹ìƒ‰ ì¸í”„ë¼ë¥¼ í™œìš©í•œ ì§€ì†ê°€ëŠ¥í•œ ë„ì‹œì„¤ê³„ ë°©ë²•ë¡ ì´ ë„ì‹œ í™˜ê²½ ë¬¸ì œ í•´ê²°ì— íš¨ê³¼ì ì„ì„ í™•ì¸í•˜ì˜€ë‹¤.
        í–¥í›„ ì •ì±…ì  ì§€ì›ê³¼ ì‹œë¯¼ ì°¸ì—¬ë¥¼ í†µí•´ ë”ìš± í™•ëŒ€ ì ìš©ë  í•„ìš”ê°€ ìˆë‹¤."""
    }

    # ì²˜ë¦¬ ê²°ê³¼ ì‹œì—°
    enhanced_papers = []

    for paper in demo_papers:
        print(f'{"="*80}')
        print(f'ğŸ“„ ë…¼ë¬¸: {paper["title"]}')
        print(f'ğŸ‘¥ ì €ì: {paper["authors"]}')
        print(f'ğŸ“– ì¶œíŒ: {paper["publication"]} ({paper["publication_year"]})')
        print(f'ğŸ”— ID: {paper["dbpia_id"]}')
        print(f'{"="*80}')

        # 1. ì´ˆë¡ ì²˜ë¦¬
        original_abstract = paper["abstract"]
        enhanced_abstract = enhanced_abstracts.get(paper["dbpia_id"], original_abstract)

        original_quality = demo_validate_abstract_quality(original_abstract)
        enhanced_quality = demo_validate_abstract_quality(enhanced_abstract)

        print('\nğŸ“„ ì´ˆë¡ ì²˜ë¦¬ ê²°ê³¼:')
        print(f'  ğŸ”¸ ì›ë³¸ ì´ˆë¡ ê¸¸ì´: {len(original_abstract)}ì (í’ˆì§ˆ: {original_quality:.1f}/10)')
        print(f'  ğŸ”¸ ê°œì„  ì´ˆë¡ ê¸¸ì´: {len(enhanced_abstract)}ì (í’ˆì§ˆ: {enhanced_quality:.1f}/10)')
        print(f'  ğŸ”¸ ì´ˆë¡ ê°œì„ ìœ¨: {((enhanced_quality - original_quality) / original_quality * 100) if original_quality > 0 else 0:.1f}%')

        print('\n  ğŸ“ ê°œì„ ëœ ì´ˆë¡:')
        print(f'     {enhanced_abstract[:300]}...')

        # 2. ì›ë¬¸ ì²˜ë¦¬
        full_text = full_text_samples.get(paper["dbpia_id"], "")
        text_quality = demo_calculate_extraction_quality(full_text) if full_text else 0

        print('\nğŸ“– ì›ë¬¸ ì²˜ë¦¬ ê²°ê³¼:')
        if full_text:
            print(f'  ğŸ”¸ ì›ë¬¸ ê¸¸ì´: {len(full_text):,}ì')
            print(f'  ğŸ”¸ ì›ë¬¸ í’ˆì§ˆ: {text_quality:.1f}/10')
            print('  ğŸ”¸ ì¶”ì¶œ ë°©ë²•: pdfplumber (ë°ëª¨)')
            print('  ğŸ”¸ ì¶”ì¶œ ìƒíƒœ: âœ… success')

            print('\n  ğŸ“ ì›ë¬¸ ë¯¸ë¦¬ë³´ê¸°:')
            print(f'     {full_text[:500]}...')
        else:
            print('  ğŸ”¸ ì›ë¬¸ ìƒíƒœ: âŒ PDF ì ‘ê·¼ ë¶ˆê°€ (ë°ëª¨)')

        # ë…¼ë¬¸ ë°ì´í„° ì—…ë°ì´íŠ¸
        enhanced_paper = paper.copy()
        enhanced_paper.update({
            'original_abstract': original_abstract,
            'abstract': enhanced_abstract,
            'abstract_enhanced': True,
            'abstract_quality_score': enhanced_quality,
            'full_text': full_text,
            'text_quality_score': text_quality,
            'extraction_status': 'success' if full_text else 'failed'
        })
        enhanced_papers.append(enhanced_paper)

        print(f'\n{"="*80}\n')

    # ì „ì²´ ìš”ì•½
    total_papers = len(enhanced_papers)
    enhanced_abstracts_count = sum(1 for p in enhanced_papers if p.get('abstract_enhanced', False))
    successful_extractions = sum(1 for p in enhanced_papers if p.get('extraction_status') == 'success')

    print('ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½:')
    print(f'  ğŸ”¸ ì´ ì²˜ë¦¬ ë…¼ë¬¸: {total_papers}ê°œ')
    print(f'  ğŸ”¸ ì´ˆë¡ ê°œì„ : {enhanced_abstracts_count}/{total_papers}ê°œ ({enhanced_abstracts_count/total_papers*100:.1f}%)')
    print(f'  ğŸ”¸ ì›ë¬¸ ì¶”ì¶œ: {successful_extractions}/{total_papers}ê°œ ({successful_extractions/total_papers*100:.1f}%)')

    avg_abstract_quality = sum(p.get('abstract_quality_score', 0) for p in enhanced_papers) / len(enhanced_papers)
    print(f'  ğŸ”¸ í‰ê·  ì´ˆë¡ í’ˆì§ˆ: {avg_abstract_quality:.1f}/10')

    text_qualities = [p.get('text_quality_score', 0) for p in enhanced_papers if p.get('text_quality_score')]
    if text_qualities:
        avg_text_quality = sum(text_qualities) / len(text_qualities)
        print(f'  ğŸ”¸ í‰ê·  ì›ë¬¸ í’ˆì§ˆ: {avg_text_quality:.1f}/10')

    print('\nğŸ¯ ì£¼ìš” ê°œì„ ì‚¬í•­:')
    print('  âœ… API ê¸°ë³¸ ì´ˆë¡ â†’ ìƒì„¸ í˜ì´ì§€ ì™„ì „ ì´ˆë¡ ì¶”ì¶œ')
    print('  âœ… PDF ë‹¤ìš´ë¡œë“œ â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ í’ˆì§ˆ í‰ê°€')
    print('  âœ… ë‹¤ì¤‘ ì¶”ì¶œ ë°©ë²• ì§€ì› (pdfplumber, PyPDF2)')
    print('  âœ… ìë™ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ë° ê²€ì¦')
    print('  âœ… íŒŒì¼ ê´€ë¦¬ ë° ì¤‘ë³µ ë°©ì§€')

if __name__ == "__main__":
    asyncio.run(demo_extraction_capabilities())
