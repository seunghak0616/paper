from __future__ import annotations

import json
from pathlib import Path

import openai
from pypdf import PdfReader
from tqdm import tqdm

from app.models import Paper, PaperChunk, SessionLocal

# --- ì„¤ì • ---
BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data"
PDF_DIR = DATA_DIR / "pdfs"
META_PATH = DATA_DIR / "metadata.json"
# OpenAI í´ë¼ì´ì–¸íŠ¸ëŠ” .env íŒŒì¼ì˜ OPENAI_API_KEYë¥¼ ìë™ìœ¼ë¡œ ì½ìŒ
client = openai.OpenAI()
CHUNK_SIZE = 500  # í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆŒ ê¸€ì ìˆ˜ ê¸°ì¤€
EMBEDDING_MODEL = "text-embedding-ada-002"


def split_text_into_chunks(text: str, chunk_size: int) -> list[str]:
    """ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì§€ì •ëœ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""
    if not text:
        return []

    # ë¨¼ì € ë¬¸ë‹¨ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ë„ˆë¬´ ê¸´ ë¬¸ë‹¨ì€ ë¬¸ì¥ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    chunks = []
    paragraphs = text.split("\n\n")
    for p in paragraphs:
        if len(p) <= chunk_size:
            chunks.append(p.strip())
        else:
            sentences = p.split(". ")
            current_chunk = ""
            for s in sentences:
                if len(current_chunk) + len(s) + 1 > chunk_size:
                    chunks.append(current_chunk.strip())
                    current_chunk = s + ". "
                else:
                    current_chunk += s + ". "
            if current_chunk:
                chunks.append(current_chunk.strip())

    return [c for c in chunks if c]


def process_pdf_and_embed(paper_meta: dict, db_session) -> None:
    """ê°œë³„ PDFë¥¼ ì²˜ë¦¬í•˜ê³ , ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì„ë² ë”©ê³¼ í•¨ê»˜ DBì— ì €ì¥"""
    pdf_path = PDF_DIR / (paper_meta["file_name"])
    if not pdf_path.exists():
        print(f"âš ï¸ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    # 1. Paper ë ˆì½”ë“œ ìƒì„±
    db_paper = Paper(
        title=paper_meta["title"],
        author=paper_meta.get("author"),
        publisher=paper_meta.get("publisher"),
        # TODO: ë‚ ì§œ í˜•ì‹ íŒŒì‹± í•„ìš”
        # published_date=paper_meta.get("published_date"),
        abstract=paper_meta.get("abstract"),
        pdf_path=str(pdf_path),
    )
    db_session.add(db_paper)
    db_session.commit()
    db_session.refresh(db_paper)

    print(f"ğŸ“„ '{db_paper.title}' ì²˜ë¦¬ ì¤‘...")

    # 2. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
    try:
        reader = PdfReader(pdf_path)
        full_text = "\n".join([page.extract_text() for i, page in enumerate(reader.pages) if i < 5]) # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5í˜ì´ì§€ë§Œ
    except Exception as e:
        print(f"ğŸ”¥ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {pdf_path}, ì˜¤ë¥˜: {e}")
        return

    # 3. í…ìŠ¤íŠ¸ ì²­í‚¹
    chunks = split_text_into_chunks(full_text, CHUNK_SIZE)
    if not chunks:
        print(f"â„¹ï¸ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    print(f"  - {len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í• ë¨")

    # 4. ê° ì²­í¬ ì„ë² ë”© ìƒì„± ë° ì €ì¥
    try:
        # í•œ ë²ˆì— ì—¬ëŸ¬ ì²­í¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ API í˜¸ì¶œ ìµœì†Œí™”
        response = client.embeddings.create(input=chunks, model=EMBEDDING_MODEL)
        embeddings = [item.embedding for item in response.data]

        for i, chunk_text in enumerate(chunks):
            db_chunk = PaperChunk(
                paper_id=db_paper.id,
                chunk_text=chunk_text,
                embedding=embeddings[i],
                # TODO: ì •í™•í•œ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì  ê¸°ëŠ¥ ì¶”ê°€
                page_number=i // 5 + 1, # ì„ì‹œ í˜ì´ì§€ ë²ˆí˜¸
            )
            db_session.add(db_chunk)

        db_session.commit()
        print("  - âœ… ì„ë² ë”© ì €ì¥ ì™„ë£Œ")

    except Exception as e:
        print(f"ğŸ”¥ ì„ë² ë”© ìƒì„± ë˜ëŠ” ì €ì¥ ì‹¤íŒ¨: {e}")
        db_session.rollback()


def main():
    """
    metadata.jsonì„ ì½ì–´ ëª¨ë“  ë…¼ë¬¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  DBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    if not META_PATH.exists():
        print("âŒ metadata.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í¬ë¡¤ëŸ¬ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    papers_meta = json.loads(META_PATH.read_text("utf-8"))

    db_session = SessionLocal()
    try:
        with tqdm(total=len(papers_meta), desc="ë…¼ë¬¸ ì²˜ë¦¬ ì¤‘") as pbar:
            for paper_meta in papers_meta:
                # ì´ë¯¸ ì²˜ë¦¬ëœ ë…¼ë¬¸ì¸ì§€ í™•ì¸
                existing_paper = db_session.query(Paper).filter_by(title=paper_meta["title"]).first()
                if existing_paper:
                    print(f"ì´ë¯¸ ì²˜ë¦¬ëœ ë…¼ë¬¸ì…ë‹ˆë‹¤: {paper_meta['title']}")
                    pbar.update(1)
                    continue

                process_pdf_and_embed(paper_meta, db_session)
                pbar.update(1)

        print("âœ… ëª¨ë“  ë…¼ë¬¸ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    finally:
        db_session.close()


if __name__ == "__main__":
    main()
